{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f0c47200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from  datetime import datetime, timedelta\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "config = {\n",
    "    'READ_DATASETS_FULL': False,\n",
    "    'LOAD_DATASETS_FULL': True,\n",
    "    'ReGen': False\n",
    "    \n",
    "}\n",
    "legal_tag = ['2','6','10','12','13','15','18','19','21','22','25','26','36','37','39','48']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2aba4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['READ_DATASETS_FULL']:\n",
    "    df = pd.read_csv('tbrain_cc_training_48tags_hash_final.csv')\n",
    "    #!pip install --upgrade tables\n",
    "    print(df.shape)\n",
    "    #df.to_hdf('df_all.hdf',key = 's',mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1bda22b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cc07c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            elif str(col_type)[:5] == 'float':\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cad464c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin data numbers:  32975653\n",
      "Mem. usage decreased to 4088.24 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Legal_tag: tags that output required\n",
    "if config['LOAD_DATASETS_FULL']:\n",
    "    #df = pd.read_hdf('df_all.hdf', 's')\n",
    "    df = pd.read_hdf('reduced_all.hdf', 's')\n",
    "    print('origin data numbers: ', len(df))\n",
    "    df = reduce_mem_usage(df, verbose=True)\n",
    "    #df.to_hdf('reduced_all.hdf',key = 's',mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "07fb0997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n",
      "int32\n",
      "object\n",
      "int16\n",
      "float64\n",
      "int16\n",
      "int16\n",
      "int8\n",
      "int16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int16\n",
      "int8\n",
      "int16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float16\n",
      "float64\n",
      "float16\n",
      "float16\n",
      "int8\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "        print(df[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2edc153a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data after reduction:  22130579\n"
     ]
    }
   ],
   "source": [
    "df2 = df[df['shop_tag'].isin(legal_tag)]\n",
    "#df2=df.copy()\n",
    "print('data after reduction: ', len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "676b0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(df, ID):\n",
    "   \n",
    "    df_chid = df[df['chid'] == ID]\n",
    "    # sort by txn_amount(descending) and dt(ascending)\n",
    "    df_chid = df_chid.sort_values(['dt', 'txn_amt'], ascending=[True, False])\n",
    "    # sort dt \n",
    "    dt_list = list(set(df_chid.dt))\n",
    "    dt_list = sorted(dt_list)\n",
    "    df_train = pd. DataFrame() \n",
    "    # ============feature extraction ==============\n",
    "    new_column = list(df_chid.keys())\n",
    "    tag_cnt_col = ['tag' + str(l) + 'cnt' for l in legal_tag]\n",
    "    tag_amt_col = ['tag' + str(l) + 'amt' for l in legal_tag]\n",
    "    new_column.extend(tag_cnt_col)\n",
    "    new_column.extend(tag_amt_col)\n",
    "    new_column.append('label')\n",
    "    #print(new_column)\n",
    "    df_all = []\n",
    "    for idx, dt in enumerate(dt_list):\n",
    "        # label: next month largest shop tag\n",
    "        df_dt = df_chid[df_chid['dt'] == dt] \n",
    "        if idx != len(dt_list) - 1:\n",
    "            label = df_chid[df_chid['dt'] == dt_list[idx+1]].shop_tag.values[0]\n",
    "        amt_total = df_dt['txn_amt'].sum()\n",
    "        cnt_total = df_dt['txn_cnt'].sum()\n",
    "        tag_history = list(df_dt.shop_tag.values)\n",
    "        amt = list(df_dt.txn_amt.values)\n",
    "        cnt = list(df_dt.txn_cnt.values)\n",
    "        tag_amt = dict(zip(tag_history, amt))\n",
    "        tag_cnt = dict(zip(tag_history, cnt))\n",
    "        # merge\n",
    "        df_dt =  df_dt.groupby('dt', as_index=False).mean()\n",
    "        for l in legal_tag:\n",
    "            if l in tag_history:\n",
    "                df_dt['tag_' + str(l) + '_cnt'] = tag_cnt[l]\n",
    "                df_dt['tag_' + str(l) + '_amt'] = tag_amt[l]\n",
    "            else:\n",
    "                df_dt['tag_' + str(l) + '_cnt'] = 0\n",
    "                df_dt['tag_' + str(l) + '_amt'] = 0\n",
    "        #txn_amt -> total amt\n",
    "        df_dt['txn_amt'] = amt_total\n",
    "        #txn_cnt -> total cnt\n",
    "        df_dt['txn_cnt'] = cnt_total\n",
    "        if idx != len(dt_list) - 1:\n",
    "            df_dt['label'] = label\n",
    "        df_all.append(df_dt)\n",
    "    if len(df_all) > 1:\n",
    "        df_train = pd.concat(df_all[:-1]).reset_index(drop = True)\n",
    "    \n",
    "    return df_train, df_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eff4e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_age_model(df_train, age):\n",
    "    print('--- START TRAINING AGE' + str(age) + ' ---')\n",
    "    labelencoder = LabelEncoder()\n",
    "    df_train['label'] = labelencoder.fit_transform(df_train['label'])\n",
    "    print(labelencoder.classes_)\n",
    "    df_train = df_train.fillna(-1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_train.drop('label', axis = 'columns'), df_train['label'], test_size = 0.1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    # score\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    file_name = \"./model/xgb_age\" + str(age) + \".pkl\"\n",
    "    # save\n",
    "    pickle.dump(model, open(file_name, \"wb\"))\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    pred = model.predict(X_test)\n",
    "    print(model.classes_)\n",
    "    y_pred = np.array(y_pred)\n",
    "    predictions = [model.classes_[value.argsort()[-3:]] for value in y_pred]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print('Top1 accuracy: ',accuracy)\n",
    "    accuracy = [1 for yhat, y in zip(predictions, y_test) if y in yhat]\n",
    "    print(len(accuracy)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7efba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eval\n",
    "for age in range(1, 9):\n",
    "    print('--- Age ' + str(age) + ' ---')\n",
    "    trains = []\n",
    "    tests = []\n",
    "    df_age = df2[df2['age'] == age]\n",
    "    chid_a1 = list(set(df_age.chid.values))\n",
    "    if config['ReGen']:\n",
    "        for ID in tqdm(chid_a1):\n",
    "            try:\n",
    "            #print(ID)\n",
    "                train, test = gen_data(df_age, ID)\n",
    "                trains.append(train)\n",
    "                tests.append(test)\n",
    "            except:\n",
    "                print(ID)\n",
    "                break;\n",
    "        df_train = pd.concat(trains).reset_index(drop=True)\n",
    "        df_test = pd.concat(tests).reset_index(drop=True)  \n",
    "        df_train.to_pickle(\"./save/df_train\" + str(age)+ \".pkl\")\n",
    "        df_test.to_pickle(\"./save/df_test\" + str(age) + \".pkl\")\n",
    "    else:\n",
    "        df_train = pd.read_pickle(\"./save/df_train\" + str(age)+ \".pkl\")\n",
    "        df_test = pd.read_pickle(\"./save/df_test\" + str(age)+ \".pkl\")\n",
    "        print('--- FINISHED LOADING DATA ---')\n",
    "    df_train = reduce_mem_usage(df_train)\n",
    "    print('TRAIN DATA SHAPE: ', df_train.shape)\n",
    "    if True:\n",
    "        train_age_model(df_train, age)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a0e2e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(CSV=True):\n",
    "    #load model\n",
    "    print('START LOADING MODEL ...')\n",
    "    model1 = pickle.load(open(\"model/xgb_age1.pkl\", \"rb\"))\n",
    "    model2 = pickle.load(open(\"model/xgb_age2.pkl\", \"rb\"))\n",
    "    model3 = pickle.load(open(\"model/xgb_age3.pkl\", \"rb\"))\n",
    "    model4 = pickle.load(open(\"model/xgb_age4.pkl\", \"rb\"))\n",
    "    model5 = pickle.load(open(\"model/xgb_age5.pkl\", \"rb\"))\n",
    "    model6 = pickle.load(open(\"model/xgb_age6.pkl\", \"rb\"))\n",
    "    model7 = pickle.load(open(\"model/xgb_age7.pkl\", \"rb\"))\n",
    "    model8 = pickle.load(open(\"model/xgb_age8.pkl\", \"rb\"))\n",
    "    print(\"FINISHED LOADING MODEL\")\n",
    "    #reverse features\n",
    "    en = ['10' ,'12', '13', '15', '18' ,'19' ,'2', '21', '22', '25' ,'26', '36', '37', '39', '48','6']\n",
    "    ans = dict(zip(np.arange(16), en))\n",
    "    sub = pd.read_csv('submit.csv')\n",
    "    sub_id = list(sub.chid.values)\n",
    "    ttl_test = []\n",
    "    for i in range(1, 9):\n",
    "        test = pd.read_pickle(\"./save/df_test\" + str(i)+ \".pkl\")\n",
    "        ttl_test.append(test)\n",
    "    ttl_test = pd.concat(ttl_test).reset_index(drop = True)\n",
    "    users = list(ttl_test.chid.values)\n",
    "    \n",
    "    # predict answers\n",
    "    CHID = []\n",
    "    TOP = []\n",
    "\n",
    "    for age in range(1, 10):\n",
    "        test = ttl_test[ttl_test['age'] == age]\n",
    "        ID = list(test.chid.values)\n",
    "        scaler = StandardScaler()\n",
    "        test = scaler.fit_transform(test)\n",
    "        if age ==1:\n",
    "            predict = model1.predict_proba(test)\n",
    "        elif age ==2:\n",
    "            predict = model2.predict_proba(test)\n",
    "        elif age ==3:\n",
    "            predict = model3.predict_proba(test)\n",
    "        elif age ==4:\n",
    "            predict = model4.predict_proba(test)\n",
    "        elif age ==5:\n",
    "            predict = model5.predict_proba(test)\n",
    "        elif age ==6:\n",
    "            predict = model6.predict_proba(test)\n",
    "        elif age ==7:\n",
    "            predict = model7.predict_proba(test)\n",
    "        elif age ==8 or age == 9:\n",
    "            predict = model8.predict_proba(test)\n",
    "        predict = [model1.classes_[pred.argsort()[-3:]] for pred in predict]\n",
    "        predict = np.array(predict)\n",
    "        print('Age' + str(age)+ '_test_shape: ',  predict.shape)\n",
    "        CHID.extend(ID) \n",
    "        TOP.extend(predict)\n",
    "    #\n",
    "    T1 = [ans[e[2]] for e in TOP]\n",
    "    T2 = [ans[e[1]] for e in TOP]\n",
    "    T3 = [ans[e[0]] for e in TOP]\n",
    "    ID_t1 = dict(zip(CHID, T1))\n",
    "    ID_t2 = dict(zip(CHID, T2))\n",
    "    ID_t3 = dict(zip(CHID, T3))\n",
    "    #\n",
    "    b = set(users) & set(sub_id)\n",
    "    i = set(sub_id) - set(users) \n",
    "    submit_final = pd.DataFrame({'chid':sub_id})\n",
    "    \n",
    "    #improve!!\n",
    "    submit_final['top1'] = submit_final['chid'].apply(lambda t: ID_t1[t] if t not in i else 15)\n",
    "    submit_final['top2'] = submit_final['chid'].apply(lambda t: ID_t2[t] if t not in i else 48)\n",
    "    submit_final['top3'] = submit_final['chid'].apply(lambda t: ID_t3[t] if t not in i else 37)\n",
    "    #\n",
    "    print('top1 data: ', len(submit_final['top1'].values))\n",
    "    print('top2 data: ', len(submit_final['top2'].values))\n",
    "    print('top3 data: ', len(submit_final['top3'].values))\n",
    "    if CSV:\n",
    "        submit_final.to_csv('ans2.csv', index = False) \n",
    "    print(\"----FINISHED GOOD LUCK----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6c65ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START LOADING MODEL ...\n",
      "FINISHED LOADING MODEL\n",
      "Age1_test_shape:  (434, 3)\n",
      "Age2_test_shape:  (74260, 3)\n",
      "Age3_test_shape:  (138779, 3)\n",
      "Age4_test_shape:  (130307, 3)\n",
      "Age5_test_shape:  (92205, 3)\n",
      "Age6_test_shape:  (45171, 3)\n",
      "Age7_test_shape:  (9051, 3)\n",
      "Age8_test_shape:  (889, 3)\n",
      "Age9_test_shape:  (29, 3)\n",
      "top1 data:  500000\n",
      "top2 data:  500000\n",
      "top3 data:  500000\n",
      "----FINISHED GOOD LUCK----\n"
     ]
    }
   ],
   "source": [
    "predict_answer(CSV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0af470cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chid</th>\n",
       "      <th>top1</th>\n",
       "      <th>top2</th>\n",
       "      <th>top3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10128239</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chid top1 top2 top3\n",
       "0  10128239   10    2   25"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_final[submit_final['chid'] == 10128239]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d4a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py36': conda)",
   "language": "python",
   "name": "python3711jvsc74a57bd082f90a6d6086172460f4c9c1e1a219fdde808fd64cbe4fc0c473da247502f162"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
